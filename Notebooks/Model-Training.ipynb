{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8698295,"sourceType":"datasetVersion","datasetId":5216683},{"sourceId":8674462,"sourceType":"datasetVersion","datasetId":5199276}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_absolute_error\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T14:51:13.717007Z","iopub.execute_input":"2024-06-15T14:51:13.717484Z","iopub.status.idle":"2024-06-15T14:51:13.722880Z","shell.execute_reply.started":"2024-06-15T14:51:13.717453Z","shell.execute_reply":"2024-06-15T14:51:13.721786Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Paths to videos and directories\ntrain_video_path = '/kaggle/input/q3-computer-vision/train.mp4'\ntest_video_path = '/kaggle/input/q3-computer-vision/test.mp4'\ntrain_frames_dir = '/kaggle/input/optical-flow-dataset/train_frames'\ntest_frames_dir = '/kaggle/input/optical-flow-dataset/test_frames'\ntrain_flows_dir = '/kaggle/input/optical-flow-dataset/train_flows'\ntest_flows_dir = '/kaggle/input/optical-flow-dataset/test_flows'\ntrain_labels_file = '/kaggle/input/q3-computer-vision/train.txt'\ntest_labels_file = '/kaggle/input/q3-computer-vision/test.txt'\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T14:51:16.423545Z","iopub.execute_input":"2024-06-15T14:51:16.423891Z","iopub.status.idle":"2024-06-15T14:51:16.428996Z","shell.execute_reply.started":"2024-06-15T14:51:16.423864Z","shell.execute_reply":"2024-06-15T14:51:16.427999Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport os\nimport numpy as np\nfrom torchvision import transforms\nfrom PIL import Image\n\nclass CarSpeedDataset(Dataset):\n    def __init__(self, frames_dir, flows_dir, labels_file, frame_ratio=0.1, transform=None):\n        self.frames_dir = frames_dir\n        self.flows_dir = flows_dir\n        self.labels = self.load_labels(labels_file)\n        self.frame_ratio = frame_ratio\n        self.transform = transform\n        self.use_frame = np.random.rand(len(self.labels)) < self.frame_ratio\n\n    def load_labels(self, labels_file):\n        with open(labels_file, 'r') as file:\n            labels = [float(line.strip()) for line in file]\n        return labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        frame_path = os.path.join(self.frames_dir, f'frame_{idx+1:04d}.jpg')\n        flow_path = os.path.join(self.flows_dir, f'flow_{idx+1:04d}.jpg')\n\n        if not os.path.exists(frame_path) or not os.path.exists(flow_path):\n            print(f\"Skipping index {idx}: File not found\")\n            return self.__getitem__((idx + 1) % len(self))\n\n        frame = Image.open(frame_path).convert('RGB')\n        flow = Image.open(flow_path).convert('RGB')\n\n        if self.transform:\n            frame = self.transform(frame)\n            flow = self.transform(flow)\n\n        # Use 10% frames and 90% flows\n        if self.use_frame[idx]:\n            input_data = frame\n        else:\n            input_data = flow\n\n        label = self.labels[idx]\n\n        return input_data, label\n\n# Data transformations\ndata_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\n\ntrain_dataset = CarSpeedDataset(train_frames_dir, train_flows_dir, train_labels_file, transform=data_transforms)\ntest_dataset = CarSpeedDataset(test_frames_dir, test_flows_dir, test_labels_file, transform=data_transforms)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:14:26.951200Z","iopub.execute_input":"2024-06-15T15:14:26.951862Z","iopub.status.idle":"2024-06-15T15:14:26.982999Z","shell.execute_reply.started":"2024-06-15T15:14:26.951830Z","shell.execute_reply":"2024-06-15T15:14:26.982302Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass SpeedPredictionModel(nn.Module):\n    def __init__(self):\n        super(SpeedPredictionModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # Adjusted input size\n        self.fc2 = nn.Linear(128, 1)\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = SpeedPredictionModel().cuda()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:14:30.981937Z","iopub.execute_input":"2024-06-15T15:14:30.982313Z","iopub.status.idle":"2024-06-15T15:14:31.049003Z","shell.execute_reply.started":"2024-06-15T15:14:30.982282Z","shell.execute_reply":"2024-06-15T15:14:31.048297Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\n# Define loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch+1}/{num_epochs}'):\n        inputs, labels = inputs.cuda(), labels.float().cuda()  # Ensure labels are cast to float\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        outputs = outputs.squeeze()  # Remove unnecessary dimension\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:14:31.399625Z","iopub.execute_input":"2024-06-15T15:14:31.399918Z","iopub.status.idle":"2024-06-15T15:58:52.716872Z","shell.execute_reply.started":"2024-06-15T15:14:31.399893Z","shell.execute_reply":"2024-06-15T15:58:52.715904Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Training Epoch 1/10:  30%|███       | 193/638 [02:01<04:36,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1/10:  75%|███████▌  | 481/638 [05:18<01:43,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1/10: 100%|██████████| 638/638 [07:07<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 45.147321488790006\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/10:  15%|█▌        | 98/638 [00:39<03:56,  2.29it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/10:  41%|████      | 263/638 [01:45<02:34,  2.43it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/10: 100%|██████████| 638/638 [04:10<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 15.123698566400893\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/10:  10%|█         | 64/638 [00:25<03:52,  2.47it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/10:  19%|█▉        | 124/638 [00:48<03:22,  2.54it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/10: 100%|██████████| 638/638 [04:08<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 6.987230572580917\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/10:  12%|█▏        | 77/638 [00:30<03:38,  2.57it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/10:  77%|███████▋  | 492/638 [03:10<00:58,  2.51it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/10: 100%|██████████| 638/638 [04:07<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 4.150655171153687\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/10:  17%|█▋        | 110/638 [00:42<03:19,  2.65it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/10:  99%|█████████▊| 629/638 [04:07<00:03,  2.58it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/10: 100%|██████████| 638/638 [04:10<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 2.849868842146613\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/10:  58%|█████▊    | 368/638 [02:23<01:45,  2.55it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/10:  85%|████████▌ | 544/638 [03:31<00:37,  2.50it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/10: 100%|██████████| 638/638 [04:07<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 1.9983090461234687\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/10:  17%|█▋        | 107/638 [00:41<03:19,  2.66it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/10:  87%|████████▋ | 553/638 [03:34<00:34,  2.48it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/10: 100%|██████████| 638/638 [04:07<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 1.5659848787941528\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/10:  33%|███▎      | 213/638 [01:21<02:40,  2.65it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/10:  94%|█████████▍| 602/638 [03:53<00:14,  2.55it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/10: 100%|██████████| 638/638 [04:06<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 1.3161284235951296\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/10:  67%|██████▋   | 425/638 [02:47<01:22,  2.59it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/10:  76%|███████▋  | 488/638 [03:11<01:01,  2.45it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/10: 100%|██████████| 638/638 [04:09<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 1.0412225194018463\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/10:  24%|██▍       | 154/638 [00:58<03:01,  2.67it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/10:  41%|████      | 260/638 [01:40<02:27,  2.57it/s]","output_type":"stream"},{"name":"stdout","text":"Skipping index 20398: File not found\nSkipping index 20399: File not found\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/10: 100%|██████████| 638/638 [04:05<00:00,  2.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.9207510627736119\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\ndef evaluate_model(model, test_loader):\n    model.eval()\n    predictions = []\n    ground_truths = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            predictions.extend(outputs.cpu().numpy())\n            ground_truths.extend(labels.cpu().numpy())\n\n    mae = mean_absolute_error(ground_truths, predictions)\n    print(f'Mean Absolute Error: {mae}')\n\nevaluate_model(model, test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:59:03.358652Z","iopub.execute_input":"2024-06-15T15:59:03.359016Z","iopub.status.idle":"2024-06-15T16:03:04.655993Z","shell.execute_reply.started":"2024-06-15T15:59:03.358978Z","shell.execute_reply":"2024-06-15T16:03:04.655060Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Skipping index 10796: File not found\nSkipping index 10797: File not found\nSkipping index 10797: File not found\nMean Absolute Error: 4.735054195054909\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom tqdm import tqdm\n\ndef draw_text(frame, text, position=(10, 30), font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.5, font_color=(0, 255, 0), thickness=1):\n    cv2.putText(frame, text, position, font, font_scale, font_color, thickness, cv2.LINE_AA)\n\ndef create_video_with_predictions(frames_dir, flows_dir, test_loader, model, output_path_frames, output_path_overlay, frame_size=(224, 224), fps=10):\n    model.eval()\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out_frames = cv2.VideoWriter(output_path_frames, fourcc, fps, frame_size)\n    out_overlay = cv2.VideoWriter(output_path_overlay, fourcc, fps, frame_size)\n    \n    with torch.no_grad():\n        for idx, (inputs, labels) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            inputs = inputs.cuda()\n            outputs = model(inputs)\n            predictions = outputs.cpu().numpy()\n            \n            batch_size = inputs.size(0)\n            for i in range(batch_size):\n                actual_idx = idx * test_loader.batch_size + i\n                frame_path = os.path.join(frames_dir, f'frame_{actual_idx+1:04d}.jpg')\n                flow_path = os.path.join(flows_dir, f'flow_{actual_idx+1:04d}.jpg')\n                \n                frame = cv2.imread(frame_path)\n                flow = cv2.imread(flow_path)\n                \n                if frame is None or flow is None:\n                    continue\n                \n                frame = cv2.resize(frame, frame_size)\n                flow = cv2.resize(flow, frame_size)\n                \n                predicted_speed = predictions[i][0]\n                \n                draw_text(frame, f'Predicted Speed: {predicted_speed:.2f}', position=(10, 20))\n                overlay = cv2.addWeighted(frame, 0.7, flow, 0.3, 0)\n                draw_text(overlay, f'Predicted Speed: {predicted_speed:.2f}', position=(10, 20))\n                \n                out_frames.write(frame)\n                out_overlay.write(overlay)\n    \n    out_frames.release()\n    out_overlay.release()\n\n# Directories and model loading (adjust these paths as needed)\ntest_frames_dir = '/kaggle/input/optical-flow-dataset/test_frames'\ntest_flows_dir = '/kaggle/input/optical-flow-dataset/test_flows'\noutput_path_frames = 'predicted_speed_frames.mp4'\noutput_path_overlay = 'predicted_speed_overlay.mp4'\n\n# Assuming model and test_loader are already defined and loaded\ncreate_video_with_predictions(test_frames_dir, test_flows_dir, test_loader, model, output_path_frames, output_path_overlay)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T16:28:39.042285Z","iopub.execute_input":"2024-06-15T16:28:39.043028Z","iopub.status.idle":"2024-06-15T16:32:10.907184Z","shell.execute_reply.started":"2024-06-15T16:28:39.042995Z","shell.execute_reply":"2024-06-15T16:32:10.906309Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"100%|█████████▉| 337/338 [03:31<00:00,  1.58it/s][ WARN:0@6321.214] global loadsave.cpp:241 findDecoder imread_('/kaggle/input/optical-flow-dataset/test_flows/flow_10797.jpg'): can't open/read file: check file path/integrity\n100%|██████████| 338/338 [03:31<00:00,  1.60it/s][ WARN:0@6321.214] global loadsave.cpp:241 findDecoder imread_('/kaggle/input/optical-flow-dataset/test_frames/frame_10798.jpg'): can't open/read file: check file path/integrity\n[ WARN:0@6321.214] global loadsave.cpp:241 findDecoder imread_('/kaggle/input/optical-flow-dataset/test_flows/flow_10798.jpg'): can't open/read file: check file path/integrity\n","output_type":"stream"},{"name":"stdout","text":"Skipping index 10796: File not found\nSkipping index 10797: File not found\nSkipping index 10797: File not found\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# output Files Link :","metadata":{"execution":{"iopub.status.busy":"2024-06-15T16:32:34.194378Z","iopub.execute_input":"2024-06-15T16:32:34.194736Z","iopub.status.idle":"2024-06-15T16:32:34.198951Z","shell.execute_reply.started":"2024-06-15T16:32:34.194706Z","shell.execute_reply":"2024-06-15T16:32:34.197993Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}